{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "version": "2.7.11"}, "kernelspec": {"display_name": "Python 2 with Spark 2.0", "name": "python2-spark20", "language": "python"}}, "nbformat_minor": 1, "cells": [{"metadata": {}, "source": "# LocalCart scenario part 3: Analyze customer demographics and sales data\n\nIn this notebook, you'll first analyze customer demographics, such as, age, gender, income, and location. Then you'll combine that data with sales data to examine trends for product categories, transaction types, and product popularity. You'll load data from a previous notebook as well as from a public open data set, cleanse, shape, and enrich the data, and then visualize the data with the PixieDust library. Don't worry! PixieDust graphs don't require coding. By the end of the notebook, you'll understand how to combine data to gain insights about which customers you might target to increase sales.\n\n\n<img src=\"https://raw.githubusercontent.com/wdp-beta/get-started/master/notebooks/images/nb3_static_analysis.png\"></img>\n\n\nThis notebook runs on Python 2 with Spark 2.0.\n\nBefore you run this notebook, complete the set up tasks https://datascience.ibm.com/docs/content/getting-started/WDP_Beta_Scenario.html and run these notebooks:\n1. [LocalCart scenario part 1: Creating a Kafka Producer of clickstream events](https://github.com/wdp-beta/get-started/blob/master/notebooks/localcart-scenario-part-1.ipynb)\n1. [LocalCart scenario part 2: Creating a streaming pipeline](https://github.com/wdp-beta/get-started/blob/master/notebooks/localcart-scenario-part-2.ipynb)", "cell_type": "markdown"}, {"metadata": {}, "source": "<a id=\"toc\"></a>\n## Table of contents\n\n#### [Setup](#Setup)\n[Load data into the notebook](#Load-data-into-the-notebook)\n#### [Part 1. Explore customer demographics](#part1)\n[Prepare the customer data set](#Prepare-the-customer-data-set)<br>\n[Visualize customer demographics and locations](#Visualize-customer-demographics-and-locations)<br>\n[Enrich demographic information with open data](#Enrich-demographic-information-with-open-data)<br>   \n#### [Part 2. Explore sales transactions](#part2)\n[Prepare the sales data set](#Prepare-the-sales-data-set)<br>\n[Classify sales](#Classify-sales)<br>\n[Analyze monthly sales](#Analyze-monthly-sales)<br>\n[Analyze order values](#Analyze-order-values)<br>\n[Analyze sales over time](#Analyze-sales-over-time)<br>\n[Analyze sales by demographic](#Analyze-sales-by-demographic)<br>\n[Analyze abandoned transactions](#Analyze-abandoned-transactions)\n#### [Summary and next steps](#summary)", "cell_type": "markdown"}, {"metadata": {}, "source": "## Setup\nYou need to import libraries and load the customer data into this notebook.\n\nImport the necessary libraries:", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "import pixiedust\nimport pyspark.sql.functions as func\nimport pyspark.sql.types as types\nimport re\nimport json\nimport os\nimport requests  ", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "### Load data into the notebook\n\nThe data file contains both the customer demographic data that you'll analyzed in Part 1, and the sales transaction data for Part 2.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "raw_df = pixiedust.sampleData('https://raw.githubusercontent.com/wdp-beta/get-started/master/data/customers_orders1_opt.csv')", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n<a id=\"part1\"></a>\n# Part 1. Explore customer demographics \nIn this part of the notebook, you'll prepare the customer data and then start learning about your customers by creating multiple charts and maps. ", "cell_type": "markdown"}, {"metadata": {}, "source": "## Prepare the customer data set\nYou'll create a new DataFrame with just the data you need and then cleanse and enrich the data.\n\nExtract the columns that you want, remove duplicate customers, and add a column for aggregations:", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "# Extract the customer information from the data set\n# CUSTNAME: string, GenderCode: string, ADDRESS1: string, CITY: string, STATE: string, COUNTRY_CODE: string, POSTAL_CODE: string, POSTAL_CODE_PLUS4: int, ADDRESS2: string, EMAIL_ADDRESS: string, PHONE_NUMBER: string, CREDITCARD_TYPE: string, LOCALITY: string, SALESMAN_ID: string, NATIONALITY: string, NATIONAL_ID: string, CREDITCARD_NUMBER: bigint, DRIVER_LICENSE: string, CUST_ID: int,\ncustomer_df = raw_df.select(\"CUST_ID\", \n                            \"CUSTNAME\", \n                            \"ADDRESS1\", \n                            \"ADDRESS2\", \n                            \"CITY\", \n                            \"POSTAL_CODE\", \n                            \"POSTAL_CODE_PLUS4\", \n                            \"STATE\", \n                            \"COUNTRY_CODE\", \n                            \"EMAIL_ADDRESS\", \n                            \"PHONE_NUMBER\",\n                            \"AGE\",\n                            \"GenderCode\",\n                            \"GENERATION\",\n                            \"NATIONALITY\", \n                            \"NATIONAL_ID\", \n                            \"DRIVER_LICENSE\").dropDuplicates()\n\n# append a column to the DataFrame for aggregations\ncustomer_df = customer_df.withColumn(\"count\", func.lit(1))\ncustomer_df", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Notice that the data type of the AGE column is currently a string. Convert the AGE column to a numeric data type so you can run calculations on customer age.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# ---------------------------------------\n# Cleanse age (enforce numeric data type) \n# ---------------------------------------\n\ndef getNumericVal(col):\n    \"\"\"\n    input: pyspark.sql.types.Column\n    output: the numeric value represented by col or None\n    \"\"\"\n    try:\n      return int(col)\n    except ValueError:\n      # age-33\n      match = re.match('^age\\-(\\d+)$', col)\n      if match:\n        try:\n          return int(match.group(1))\n        except ValueError:    \n          return None\n      return None  \n\ntoNumericValUDF = func.udf(lambda c: getNumericVal(c), types.IntegerType())\ncustomer_df = customer_df.withColumn(\"AGE\", toNumericValUDF(customer_df[\"AGE\"]))", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "The GenderCode column contains salutations instead of gender values. Derive the gender information for each customer based on the salutation and rename the GenderCode column to GENDER.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "# ------------------------------\n# Derive gender from salutation\n# ------------------------------\ndef deriveGender(col):\n    \"\"\" input: pyspark.sql.types.Column\n        output: \"male\", \"female\" or \"unknown\"\n    \"\"\"    \n    if col in ['Mr.', 'Master.']:\n        return 'male'\n    elif col in ['Mrs.', 'Miss.']:\n        return 'female'\n    else:\n        return 'unknown';\n    \nderiveGenderUDF = func.udf(lambda c: deriveGender(c), types.StringType())\ncustomer_df = customer_df.withColumn(\"GENDER\", deriveGenderUDF(customer_df[\"GenderCode\"]))\ncustomer_df.cache()", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n## Visualize customer demographics and locations\n\nNow you're ready explore the customer base. Using simple charts, you can quickly see these characteristics:\n * Customer demographics (gender and age)\n * Customer locations (city, state, and country)\n\nYou'll create charts with the PixieDust library:\n\n - [View customers by gender in a pie chart](#View-customers-by-gender-in-a-pie-chart)\n - [View customers by generation in a bar chart](#View-customers-by-generation-in-a-bar-chart)\n - [View customers by age in a histogram chart](#View-customers-by-age-in-a-histogram-chart)\n - [View specific information with a filter function](#View-specific-information-with-a-filter-function)\n - [View customer density by location with a map](#View-customer-density-by-location-with-a-map)", "cell_type": "markdown"}, {"metadata": {}, "source": "### View customers by gender in a pie chart\n\nRun the `display()` command and then configure the graph to show the percentages of male and female customers:\n\n1. Run the next cell. The PixieDust interactive widget appears.  \n1. Click the chart button and choose **Pie Chart**. The chart options tool appears.\n1. In the chart options tool, drag `count` into the **Values** box. \n1. Move `GENDER` into the **Keys** box. \n1. In the **Aggregation** field, choose **COUNT**. \n1. Click **OK**. The pie chart appears.\n\nIf you want to make further changes, click **Options** to return to the chart options tool.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "pieChart", "valueFields": "count", "aggregation": "COUNT", "keyFields": "GENDER", "rowCount": "500", "chartsize": "50"}}}, "source": "display(customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n### View customers by generation in a bar chart\nLook at how many customers you have per \"generation.\"\n\nRun the next cell and configure the graph: \n1. Choose **Bar Chart** as the chart type.\n2. Put `GENERATION` into the **Keys** box.\n3. Put `count` into the **Values** box.\n4. Set aggregation to COUNT.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "barChart", "valueFields": "count", "aggregation": "COUNT", "keyFields": "GENERATION", "rowCount": "500", "chartsize": "51"}}}, "source": "display(customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "You can use clustering to group customers, for example by geographic location. To group generations by country, select `COUNTRY_CODE` from the **Cluster by** list. ", "cell_type": "markdown"}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n### View customers by age in a histogram chart\nA generation is a broad age range. You can look at a smaller age range with a histogram chart. A histogram is like a bar chart except each bar represents a range of numbers, called a bin. You can customize the size of the age range by adjusting the bin size. The more bins you specify, the smaller the age range.\n\nRun the next cell and configure the graph:\n1. Choose **Histogram** as the chart type.\n2. Put `AGE` into the **Keys** box and click **OK**.\n3. Use the **Bin size** slider to specify the number of the bins. Try starting with 40.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"binsize": "40", "handlerId": "histogram", "rowCount": "500", "chartsize": "60", "valueFields": "AGE"}}}, "source": "display(customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n### View specific information with a filter function\n\nYou can filter records to restrict analysis by using the `filter()` function.\n\nIf you want to view the age distribution for a specific generation, uncomment and run one of the following commands:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "histogram", "GENERATION": "Baby_Boomers", "rowCount": "500", "chartsize": "60", "valueFields": "AGE"}}, "scrolled": false}, "source": "# Data subsetting: display age distribution for a specific generation\n# (Chart type: histogram, Chart Options > Keys: AGE)\n# to run one of the command remove the # sign \n#display(customer_df.filter(\"GENERATION = 'Baby_Boomers'\"))\n#display(customer_df.filter(\"GENERATION = 'Gen_X'\"))\n#display(customer_df.filter(\"GENERATION = 'Gen_Y'\"))\n#display(customer_df.filter(\"GENERATION = 'Gen_Z'\"))", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "If you want to view the age distribution for a specific gender, uncomment and run one of the following commands:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"valueFields": "AGE", "handlerId": "histogram", "GENDER": "female", "chartsize": "60", "rowCount": "500"}}}, "source": "# Data subsetting: display age distribution by gender\n# (Chart type: histogram, Chart Options > Keys: AGE)\n#display(customer_df.filter(\"GENDER = 'female'\"))\n#display(customer_df.filter(\"GENDER = 'male'\"))", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "You can also filter by location. For example, the following command creates a new DataFrame that filters for customers from the USA:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "us_customer_df = customer_df.filter(\"COUNTRY_CODE = 'US'\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "You can pivot your analysis perspective based on aspects that are of interest to you by choosing different keys and clusters.\n\nCreate a bar chart and cluster the data.\n\nRun the next cell and configure the graph:\n1. Choose **Bar chart** as the chart type.\n2. Put `COUNTRY_CODE` into the **Keys** box.\n3. Put `count` in the **Values** box.\n4. Set Aggregation to **COUNT**.\n5. Click **OK**. The chart displays the number of US customers.\n6. From the **Cluster By** list, choose **GENDER**. The chart shows the number of customers by gender.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"legend": "true", "aggregation": "COUNT", "valueFields": "count", "rowCount": "500", "chartsize": "76", "clusterby": "GENDER", "keyFields": "COUNTRY_CODE", "handlerId": "barChart"}}}, "source": "display(us_customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now try to cluster the customers by state.\n\nA bar chart isn't the best way to show geographic location!", "cell_type": "markdown"}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n### View customer density by location with a map\nMaps are a much better way to view location data than other chart types. \n\nVisualize customer density by US state with a map.\n\nRun the next cell and configure the graph:\n1. Choose **Map** as the chart type.\n2. Put `STATE` into the **Keys** box.\n3. Put `count` in the **Values** box.\n4. Set Aggregation to **COUNT**.\n5. Click **OK**. The map displays the number of US customers.\n6. From the **Renderer** list, choose **google**.\n7. From the **Display Mode** list, choose **region**.\n8. From the **Region** list, choose `US`.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "mapView", "valueFields": "count", "aggregation": "COUNT", "keyFields": "STATE", "rowCount": "500", "chartsize": "60"}}}, "source": "display(us_customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Hover over an area to display the number of customers in each state.", "cell_type": "markdown"}, {"metadata": {"pixiedust": {"displayParams": {"handlerId": "mapView", "valueFields": "count", "aggregation": "COUNT", "keyFields": "STATE", "rowCount": "500", "chartsize": "53"}}}, "source": "You can explore more about customers in each state by changing the aggregation method. \n\nLook at customer age ranges (avg, minimum, and maximum) by state.\n\nRun the next cell and configure the graph:\n1. Choose **Map** as the chart type.\n2. Put `STATE` into the **Keys** box.\n3. Put `AGE` in the **Values** box.\n4. Set Aggregation to **AVG**, **MAX**, or **MIN**.\n5. Click **OK**. The map displays.\n6. From the **Renderer** list, choose **google**.\n7. From the **Display Mode** list, choose **region**.\n8. From the **Region** list, choose `US`.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "mapView", "valueFields": "AGE", "aggregation": "AVG", "keyFields": "STATE", "rowCount": "500", "chartsize": "60"}}}, "source": "display(us_customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n## Enrich demographic information with open data\nYou can easily combine other sources of data with your existing data. There's a lot of publicly available open data sets that can be very helpful. For example, knowing the approximate income level of your customers might help you target your marketing campaigns.\n\nRun the next cell to load [this data set](https://apsportal.ibm.com/exchange/public/entry/view/beb8c30a3f559e58716d983671b70337) from the United States Census Bureau into your notebook. The data set contains US household income statistics compiled at the zip code geography level.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "# Load median income information for all US ZIP codes from a public source\nincome_df = pixiedust.sampleData('https://apsportal.ibm.com/exchange-api/v1/entries/beb8c30a3f559e58716d983671b70337/data?accessKey=1c0b5b6d465fefec1ab529fde04997af')", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now cleanse the income data set to remove the data that you don't need. Create a new DataFrame for this data:\n - The zip code, extracted from the GEOID column.\n - The column B19049e1, which contains the median household income for 2013.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "# ------------------------------\n# Helper: Extract ZIP code\n# ------------------------------\ndef extractZIPCode(col):\n    \"\"\" input: pyspark.sql.types.Column containing a geo code, like '86000US01001'\n        output: ZIP code\n    \"\"\"\n    m = re.match('^\\d+US(\\d\\d\\d\\d\\d)$',col)\n    if m:\n        return m.group(1)\n    else:\n        return None    \n    \ngetZIPCodeUDF = func.udf(lambda c: extractZIPCode(c), types.StringType())\nincome_df = income_df.select('GEOID', 'B19049e1').withColumnRenamed('B19049e1', 'MEDIAN_INCOME_IN_ZIP').withColumn(\"ZIP\", getZIPCodeUDF(income_df['GEOID']))\nincome_df", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now perform a left outer join on the customer data set with the income data set, using the zip code as the join condition. For the complete syntax of joins, go to the <a href=\"https://spark.apache.org/docs/1.5.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame\" target=\"_blank\" rel=\"noopener noreferrer\">pyspark DataFrame documentation</a> and scroll down to the `join` syntax. ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "us_customer_df = us_customer_df.join(income_df, us_customer_df.POSTAL_CODE == income_df.ZIP, 'left_outer').drop('GEOID').drop('ZIP')", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now you can visualize the income distribution of your customers by zip code.\n Visualize income distribution for our customers.\nRun the next cell and configure the graph:\n1. Choose **Histogram** as the chart type.\n2. Put `MEDIAN_INCOME_IN_ZIP` into the **Keys** box and click **OK**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"binsize": "25", "handlerId": "histogram", "rowCount": "500", "chartsize": "52", "valueFields": "MEDIAN_INCOME_IN_ZIP"}}}, "source": "display(us_customer_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "The majority of your customers live in zip codes where the median income is around 40,000 USD. ", "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": "[Back to Table of Contents](#toc)\n<a id=\"part2\"></a>\n# Part 2. Explore sales transactions\nIn this part of the notebook, you'll analyze time-based sales transactions summaries.\n\nYou'll answer these questions about your sales:\n\n- Who buys which products?\n- How much money is left on the table in abandoned transactions?\n- Which products are the best sellers?", "cell_type": "markdown"}, {"metadata": {}, "source": "## Prepare the sales data set\nYou'll create a new DataFrame with just the data you need and then cleanse and enrich the data.\n\nExtract the columns that you want, remove duplicate customers, and add a column for aggregations:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# Extract sales information from raw data set\n# \nsales_df = raw_df.select(\"CUST_ID\", \n                         \"CITY\", \n                         \"STATE\", \n                         \"COUNTRY_CODE\", \n                         \"GenderCode\",\n                         \"GENERATION\",\n                         \"AGE\",\n                         \"CREDITCARD_TYPE\",\n                         \"ORDER_ID\",\n                         \"ORDER_TIME\",\n                         \"FREIGHT_CHARGES\",\n                         \"ORDER_SALESMAN\",\n                         \"ORDER_POSTED_DATE\",\n                         \"ORDER_SHIP_DATE\",\n                         \"ORDER_VALUE\",\n                         \"T_TYPE\",\n                         \"PURCHASE_TOUCHPOINT\",\n                         \"PURCHASE_STATUS\",\n                         \"ORDER_TYPE\",\n                         \"Baby Food\",\n                         \"Diapers\",\n                         \"Formula\",\n                         \"Lotion\", \n                         \"Baby wash\",\n                         \"Wipes\",\n                         \"Fresh Fruits\",\n                         \"Fresh Vegetables\",\n                         \"Beer\",\n                         \"Wine\",\n                         \"Club Soda\",\n                         \"Sports Drink\",\n                         \"Chips\",\n                         \"Popcorn\",\n                         \"Oatmeal\",\n                         \"Medicines\",\n                         \"Canned Foods\",\n                         \"Cigarettes\",\n                         \"Cheese\",\n                         \"Cleaning Products\",\n                         \"Condiments\",\n                         \"Frozen Foods\",\n                         \"Kitchen Items\",\n                         \"Meat\",\n                         \"Office Supplies\",\n                         \"Personal Care\",\n                         \"Pet Supplies\",\n                         \"Sea Food\",\n                         \"Spices\").dropDuplicates()\n\n# add column containing the numeric value 1. it will be used to perform aggregations\nsales_df = sales_df.withColumn(\"count\", func.lit(1))", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Format the data:\n - Convert age values to numbers instead of strings. \n - Derive customer gender. \n - Convert the date column to a string. \n - Add columns for date processing.", "cell_type": "markdown"}, {"outputs": [], "metadata": {}, "source": "# ---------------------------------------\n# Cleanse age (enforce numeric data type) \n# ---------------------------------------\n\ndef getNumericVal(col):\n    \"\"\"\n    input: pyspark.sql.types.Column\n    output: the numeric value represented by col or None\n    \"\"\"\n    try:\n      return int(col)\n    except ValueError:\n      # age-33\n      match = re.match('^age\\-(\\d+)$', col)\n      if match:\n        try:\n          return int(match.group(1))\n        except ValueError:    \n          return None\n      return None  \n\ntoNumericValUDF = func.udf(lambda c: getNumericVal(c), types.IntegerType())\nsales_df = sales_df.withColumn(\"AGE\", toNumericValUDF(sales_df[\"AGE\"]))\n\n# ------------------------------\n# Derive gender from salutation\n# ------------------------------\ndef deriveGender(col):\n    \"\"\" input: pyspark.sql.types.Column\n        output: \"male\", \"female\" or \"unknown\"\n    \"\"\"    \n    if col in ['Mr.', 'Master.']:\n        return 'male'\n    elif col in ['Mrs.', 'Miss.']:\n        return 'female'\n    else:\n        return 'unknown';\n    \nderiveGenderUDF = func.udf(lambda c: deriveGender(c), types.StringType())\nsales_df = sales_df.withColumn(\"GENDER\", deriveGenderUDF(sales_df[\"GenderCode\"]))\n\n# ------------------------------\n# get date column as string\n# ------------------------------\ndef getDateString(datetime_col, format_string):\n    \"\"\" input: pyspark.sql.types.Column\n        input: string a strftime format string (https://docs.python.org/2/library/time.html#time.strftime)\n        output: a formatted date string\n    \"\"\"    \n    if format_string is None:\n        format_string = '%d/%m/%Y'\n    return datetime_col.strftime(format_string)\n\n# append columns to data set:\n#  - add ORDER_S_DATE (string representation of the order date - to address a PixieDust limitation)\n#  - add ORDER_DATE_YEAR (string representation of the order date year: YYYY)\n#  - add ORDER_DATE_MONTH (string representation of the order date month: YYYY-MM)\n\ngetDateStringUDF = func.udf(lambda c: getDateString(c, None), types.StringType())\nsales_df = sales_df.withColumn(\"ORDER_DATE_S\", getDateStringUDF(sales_df[\"ORDER_TIME\"]))\n\ngetYearStringUDF = func.udf(lambda c: getDateString(c,'%Y'), types.StringType())\nsales_df = sales_df.withColumn(\"ORDER_DATE_YEAR\", getYearStringUDF(sales_df[\"ORDER_TIME\"]))\n\ngetMonthStringUDF = func.udf(lambda c: getDateString(c,'%Y-%m'), types.StringType())\nsales_df = sales_df.withColumn(\"ORDER_DATE_MONTH\", getMonthStringUDF(sales_df[\"ORDER_TIME\"]))\n\n# cache the DataFrame to speed up analysis\nsales_df.cache()", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n## Classify sales\n\nYou're ready to look at sales transactions! \n\nUsing simple charts, you'll explore location metrics, transaction status types, the number of sales per location, and the average sale per location:\n\n - [Show customers by country](#Show-customers-by-country)\n - [Show transaction status for the USA](#Show-transaction-status-for-the-USA)\n - [Show completed transactions](#Show-completed-transactions)\n - [Show average order value](#Show-average-order-value)", "cell_type": "markdown"}, {"metadata": {}, "source": "### Show customers by country\nShow the number of customers for each country.\n\nRun the next cell and configure the graph:\n1. Choose **Bar chart** as the chart type.\n2. Put `COUNTRY_CODE` into the **Keys** box.\n3. Put `count` in the **Values** box.\n4. Set Aggregation to **SUM** and click **OK**. ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "barChart", "valueFields": "count", "aggregation": "SUM", "keyFields": "COUNTRY_CODE", "rowCount": "500", "chartsize": "50"}}}, "source": "display(sales_df.groupBy(\"COUNTRY_CODE\").count())", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "### Show transaction status for the USA\nTake a look at how many of the transactions are complete compared to in-progress, cancelled, and abandoned.\n\nFirst use a filter to restrict the geographical location to the USA.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# Apply optional filter 1: restrict geographic location to USA\nsales_df = sales_df.filter(\"COUNTRY_CODE = 'US'\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Show percentages for the sales transaction status types for the USA.\n\nRun the next cell and configure the graph:\n1. Choose **Pie chart** as the chart type.\n2. Put `T_TYPE` into the **Keys** box.\n3. Put `count` in the **Values** box.\n4. Set Aggregation to **SUM** and click **OK**. ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"title": "Transaction status", "handlerId": "pieChart", "valueFields": "count", "aggregation": "SUM", "keyFields": "T_TYPE", "rowCount": "500", "chartsize": "50"}}}, "source": "display(sales_df.groupBy(\"T_TYPE\").count())", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "### Show completed transactions\n\nFirst use a filter to restrict the data to completed transactions.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# apply optional transaction status filter. Subsequent analysis is limited to these types of transactions\ntxn_sales_df = sales_df.filter(\"T_TYPE = 'Complete'\")\n#txn_sales_df = sales_df.filter(\"T_TYPE = 'Cancelled'\")\n#txn_sales_df = sales_df.filter(\"T_TYPE = 'Abandoned'\")\n#txn_sales_df = sales_df.filter(\"T_TYPE = 'In-Progress'\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now show the number of completed transactions for each state in the USA, to answer the question, \"How many sales were made in state X?\"\n\nRun the next cell and configure the graph:\n1. Choose **Map** as the chart type.\n2. Put `STATE` into the **Keys** box.\n3. Put `count` in the **Values** box.\n4. Set Aggregation to **COUNT**.\n5. Click **OK**. The map displays.\n6. From the **Renderer** list, choose **google**.\n7. From the **Display Mode** list, choose **region**.\n8. From the **Region** list, choose `US`.\n\nHover over a state to display the number of sales transactions.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"aggregation": "COUNT", "valueFields": "count", "rowCount": "500", "handlerId": "mapView", "keyFields": "STATE"}}}, "source": "display(txn_sales_df)", "cell_type": "code", "execution_count": null}, {"metadata": {"scrolled": false, "pixiedust": {"displayParams": {"rendererId": "google", "title": "Sales transaction analysis", "aggregation": "COUNT", "valueFields": "count", "rowCount": "500", "chartsize": "50", "mapDisplayMode": "region", "clusterby": "COUNTRY_CODE", "keyFields": "STATE", "mapRegion": "US", "handlerId": "mapView"}}}, "source": "### Show average order value\n\nFinally, calculate the average order value, for completed transactions, for each US state. Answer the question, \"How much was the average transaction value in state X?\"\n\nRun the next cell and configure the graph:\n1. Choose **Map** as the chart type.\n2. Put `STATE` into the **Keys** box.\n3. Put `ORDER_VALUE` in the **Values** box.\n4. Set Aggregation to **AVG**.\n5. Click **OK**. The map displays.\n6. From the **Renderer** list, choose **google**.\n7. From the **Display Mode** list, choose **region**.\n8. From the **Region** list, choose `US`.\n\nHover over a state to display the average sales transaction.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"aggregation": "AVG", "valueFields": "ORDER_VALUE", "rowCount": "500", "handlerId": "mapView", "keyFields": "STATE"}}}, "source": "display(txn_sales_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n## Analyze monthly sales\nNow look at monthly sales for different demographics so you can answer these questions: How much are customers spending per month? Do men spend more than women? Do younger people splurge more than Baby Boomers?\n\nCreate a graph with monthly average sales by gender. \n \nRun the next cell and configure the graph:\n1. Choose **Bar chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `ORDER_VALUE` in the **Values** box.\n4. Set Aggregation to **SUM**.\n5. Click **OK**. The chart displays.\n6. From the **Renderer** list, choose **matplotlib**.\n7. From the **Cluster By** list, choose **GENDER**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"rendererId": "matplotlib", "orientation": "vertical", "legend": "true", "aggregation": "SUM", "valueFields": "ORDER_VALUE", "stretch": "true", "rowCount": "999999999", "chartsize": "60", "lineChartType": "subplots", "clusterby": "GENDER", "charttype": "grouped", "keyFields": "ORDER_DATE_MONTH", "timeseries": "false", "handlerId": "barChart"}}}, "source": "display(txn_sales_df)", "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true}, "source": "Explore the data! Change the **Cluster By** value to `GENERATION` to see which age range spends the most. Remove the **Cluster By** value to see the total sales by month. Or you can change the value in the **Keys** box to ORDER_DATE_S to see daily sales or ORDER_DATE_YEAR to see yearly sales.", "cell_type": "markdown"}, {"metadata": {}, "source": "[Back to Table of Contents](#toc)\n## Analyze order values\nLook at the value of orders by demographic. Do older customers spend more money?", "cell_type": "markdown"}, {"metadata": {}, "source": "Filter the data to contain only completed transactions and to remove outlier order values:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# only inspect completed transactions\nclassify_df = sales_df.filter(\"T_TYPE = 'Complete'\")\n# test data set contains synthetic outliers. remove them\nclassify_df = classify_df.filter(\"ORDER_VALUE < 9999999\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Correlate the shopping basket value with age and gender. \n\nRun the next cell and configure the graph:\n1. Choose **Scatter Plot** as the chart type.\n2. Put `AGE` into the **Keys** box\n3. Put `ORDER_VALUE` in the **Values** box.\n4. Click **OK**. The chart displays.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"chartsize": "63", "valueFields": "ORDER_VALUE", "rowCount": "500", "handlerId": "scatterPlot", "keyFields": "AGE"}}}, "source": "display(classify_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "It looks like older customers tend to place orders with higher values.\n\n[Back to Table of Contents](#toc)", "cell_type": "markdown"}, {"metadata": {}, "source": "## Analyze sales over time\nAnalyze your sales for trends over time. Which products are selling well in which month? Compare sales numbers for multiple product categories and identify seasonal trends.\n\nCreate a `category_columns` DataFrame so that you can group products by category:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# identify metadata columns in this data set\nmetadata_columns = [\n                    'CUST_ID', \n                    'CITY', \n                    'count',\n                    'STATE', \n                    'COUNTRY_CODE', \n                    'GenderCode', \n                    'GENDER',\n                    'GENERATION',\n                    'AGE',\n                    'CREDITCARD_TYPE',\n                    'ORDER_DATE_S',\n                    'ORDER_DATE_YEAR',\n                    'ORDER_DATE_MONTH',\n                    'ORDER_ID',\n                    'ORDER_TIME',\n                    'FREIGHT_CHARGES',\n                    'ORDER_SALESMAN',\n                    'ORDER_POSTED_DATE',\n                    'ORDER_SHIP_DATE',\n                    'ORDER_VALUE',\n                    'T_TYPE',\n                    'PURCHASE_TOUCHPOINT',\n                    'PURCHASE_STATUS',\n                    'ORDER_TYPE',\n                    'GENERATION'\n                    ]\n\n# identify item category columns\ncategory_columns = []\nfor data_column in sales_df.columns:\n    if data_column not in metadata_columns:\n        category_columns.append(data_column)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Create a DataFrame that contains monthly sales totals by product category:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "exprs = {x: \"sum\" for x in category_columns}\ncategory_count_df = sales_df.groupBy(\"ORDER_DATE_MONTH\").agg(exprs).alias(\"col\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Compare product categories for each month.\n\nRun the next cell and configure the graph:\n1. Choose **Bar Chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `sum(Fresh Vegetables)`, `sum(Fresh Fruits)`, and `sum(Sea Food)` in the **Values** box.\n4. Set the Aggregation to **SUM**. \n4. Click **OK**. The chart displays.\n5. From the **Type** list, choose **grouped**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"aggregation": "SUM", "valueFields": "sum(Fresh Vegetables),sum(Fresh Fruits),sum(Sea Food)", "rowCount": "500", "chartsize": "70", "charttype": "grouped", "keyFields": "ORDER_DATE_MONTH", "timeseries": "false", "handlerId": "barChart"}}}, "source": "display(category_count_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Customers spend a lot more money on seafood than fresh vegetables or fruit. Change the categories to compare products. Try changing the **Type** to **stacked** or **subplots** to see how you can configure your graph.\n\n[Back to Table of Contents](#toc)", "cell_type": "markdown"}, {"metadata": {}, "source": "## Analyze sales by demographic\nYou can find out which demographic group purchases items in a specific product category. \n\nFind out whether women or men purchase more fresh vegetables.", "cell_type": "markdown"}, {"metadata": {}, "source": "Run the next cell and configure the graph:\n1. Choose **Bar Chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `Fresh Vegetables` in the **Values** box.\n4. Set the Aggregation to **COUNT**. \n5. Click **OK**. The chart displays.\n6. From the **Cluster By** list, choose **GENDER**.\n7. From the **Type** list, choose **grouped**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"aggregation": "COUNT", "valueFields": "Fresh Vegetables", "rowCount": "500", "chartsize": "70", "clusterby": "GENDER", "charttype": "grouped", "keyFields": "ORDER_DATE_MONTH", "handlerId": "barChart"}}}, "source": "display(classify_df.filter(classify_df[\"Fresh Vegetables\"] > 0))", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Women buy more fresh vegetables than men do. Now find further insights by changing the value to a different category. For example, change the product to diapers and the clustering to generation to find out whether young people are buying more diapers than older people. \n\n[Back to Table of Contents](#toc)", "cell_type": "markdown"}, {"metadata": {}, "source": "## Analyze abandoned transactions\nUnderstanding abandoned transactions can help you target changes to prevent them. You need to know what kind of customer is more likely to abandon a transaction, and under what circumstances. \n\n - [Compare abandoned to completed transactions over time](#Compare-abandoned-to-completed-transactions-over-time)\n - [Find the value of abandoned transactions](#Find-the-value-of-abandoned-transactions)\n - [Analyze product categories for abandoned transactions](#Analyze-product-categories-for-abandoned-transactions)", "cell_type": "markdown"}, {"metadata": {}, "source": "### Compare abandoned to completed transactions over time\n\nSet a variable to specify abandoned transactions. Later, you can change the value of the `transaction_type` variable to compare other types of transactions, for example, cancelled transactions.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "transaction_type = 'Abandoned'", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Create a DataFrame that contains information about completed transactions and abandoned transactions:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "abandoned_df = sales_df.filter(\"T_TYPE = 'Complete' OR T_TYPE = '\" + transaction_type + \"'\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Compare the number of completed transactions with the number of abandoned transactions.\n\nRun the next cell and configure the graph:\n1. Choose **Bar Chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `count` in the **Values** box.\n4. Set the Aggregation to **SUM**. \n5. Click **OK**. The chart displays.\n6. From the **Cluster By** list, choose **T_TYPE**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"aggregation": "SUM", "valueFields": "count", "rowCount": "500", "chartsize": "72", "clusterby": "T_TYPE", "charttype": "grouped", "keyFields": "ORDER_DATE_MONTH", "handlerId": "barChart"}}}, "source": "display(abandoned_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now you can drill down to find out more about abandoned transactions:\n - Which age range abandons the most transactions?\n - What method of ordering results in the most abandoned transactions?\n - Do frequent or infrequent customers abandon more transactions?\n\nCreate a DataFrame with only abandoned transactions (or whichever type of transactions that the `transaction_type` variable specifies):", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# create new data set comprising of all <transaction_type> sales transactions\ntx_type_sales_df = sales_df.filter(\"T_TYPE = '\" + transaction_type + \"'\")\n# test data set contains synthetic outliers. remove them\ntx_type_sales_df = tx_type_sales_df.filter(\"ORDER_VALUE < 9999999\")", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Look at the monthly value of abandoned transactions by gender.\n\nRun the next cell and configure the graph:\n1. Choose **Bar Chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `ORDER_VALUE` in the **Values** box.\n4. Set the Aggregation to **SUM**. \n5. Click **OK**. The chart displays.\n6. From the **Cluster By** list, choose **GENDER**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"legend": "true", "aggregation": "SUM", "valueFields": "ORDER_VALUE", "rowCount": "500", "chartsize": "60", "clusterby": "GENDER", "keyFields": "ORDER_DATE_MONTH", "handlerId": "barChart"}}}, "source": "display(tx_type_sales_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Now change the clustering to GENERATION (age), or PURCHASE_STATUS (frequency of purchases), or PURCHASE_TOUCHPOINT (point of sale).\n\n[Back to Table of Contents](#toc)", "cell_type": "markdown"}, {"metadata": {}, "source": "### Find the value of abandoned transactions\nThe next thing you need to know about abandoned transactions is how much they were worth.\n\nIdentify the average order value for abandoned transactions. \n\nRun the next cell and configure the graph:\n1. Choose **Histogram** as the chart type.\n2. Put `ORDER_VALUE` into the **Keys** box and click **OK**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"binsize": "114", "handlerId": "histogram", "rowCount": "500", "chartsize": "65", "valueFields": "ORDER_VALUE"}}}, "source": "display(tx_type_sales_df)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "The majority of analyzed transactions had a value of $50 or less.\n\n[Back to Table of Contents](#toc)", "cell_type": "markdown"}, {"metadata": {}, "source": "### Analyze product categories for abandoned transactions\nIdentify the product category for each month that were most often included abandoned transactions.\n \nCreate a DataFrame with the sum of the items in each category:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "exprs = {x: \"sum\" for x in category_columns}\nitem_count_df = tx_type_sales_df.groupBy(\"ORDER_DATE_MONTH\").agg(exprs)", "cell_type": "code", "execution_count": null}, {"metadata": {}, "source": "Compare the amount of abandoned orders for fresh vegetables and canned foods.\n\nRun the next cell and configure the graph:\n1. Choose **Bar Chart** as the chart type.\n2. Put `ORDER_DATE_MONTH` into the **Keys** box\n3. Put `sum(Fresh Vegetables` and `sum(Canned Foods)` in the **Values** box.\n4. Set the Aggregation to **SUM**. \n5. Click **OK**. The chart displays.\n6. From the **Type** list, choose **grouped**.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"pixiedust": {"displayParams": {"handlerId": "barChart", "valueFields": "sum(Fresh Vegetables),sum(Canned Foods)", "aggregation": "SUM", "keyFields": "ORDER_DATE_MONTH", "rowCount": "500", "chartsize": "70"}}}, "source": "display(item_count_df)", "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true}, "source": "[Back to Table of Contents](#toc)\n<a id=\"summary\"></a>\n## Summary and next steps\n\nYou've learned how to cleanse, shape, enrich, and visualize customer and sales data to find valuable insights. \n\nNext, learn how to analyze click-stream data in [Notebook 3b: Static clickstream analysis](https://github.com/wdp-beta/get-started/blob/master/notebooks/localcart-scenario-part-3b.ipynb).\n\n### Authors\nPatrick Titzler is a customer advocate for Watson Data Platform at IBM.\n\n<hr>\nCopyright &copy; IBM Corp. 2017. This notebook and its source code are released under the terms of the MIT License.", "cell_type": "markdown"}], "nbformat": 4}